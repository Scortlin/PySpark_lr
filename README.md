# Быков В.В. БД-251м Вариант 7

### Описание задачи
Выполнить операции загрузки данных в распределенную файловую систему, провести очистку и предобработку данных. 
Для варианта 7 необходимо звгрузить брошенных и оплаченных корзин и найти топ-5 товаров, дежащих в брошенных корзинах.
Выполнить аналитические запросы с использованием Spark SQL (определить пары товаров,которые чаще всего покупают вместе).
Визуализировать граф связей между топ-10 товарами для поддержки принятия управленческих решений.

### Инструкция по запуску
Шаг 1. Запуск кластера
В терминале выполните вход и запуск служб:

sudo su - hadoop
start-dfs.sh
start-yarn.sh

Шаг 2. Проверка работы
Убедитесь, что процессы запущены (NameNode, DataNode, ResourceManager, NodeManager):
jps
Веб-интерфейсы для мониторинга:
HDFS NameNode: http://localhost:9870
YARN ResourceManager: http://localhost:8088

Шаг 3. Подготовка HDFS и загрузка данных
Вам необходимо создать директорию в распределенной файловой системе и загрузить туда исходные данные (датасеты).
Создание директорий:

Создание папки пользователя (пример)
hdfs dfs -mkdir -p /user/hadoop/lab_01/input

Настройка прав доступа (при необходимости)
hdfs dfs -chmod 775 /user/hadoop/lab_01
Загрузка данных: Предположим, ваши скачанные датасеты (CSV) находятся локально в ~/Downloads/data.

hdfs dfs -put /home/hadoop/Downloads/data/*.csv /user/hadoop/lab_01/input/
Проверка загрузки:

hdfs dfs -ls /user/hadoop/lab_01/input/

Шаг 4. Выполнение lab_01.ipynb в JupyterLab

Шаг 5. Завершение работы (после выполнения всех заданий)
stop-yarn.sh
stop-dfs.sh
Или полная остановка
stop-all.sh

### Ссылка на источник данных
https://www.kaggle.com/datasets/acostasg/random-shopping-cart
